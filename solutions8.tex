%% LyX 2.2.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{color}
\usepackage{babel}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=true]
 {hyperref}
\usepackage{breakurl}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage[margin=1in]{geometry}

\makeatother

\begin{document}

\title{Math 525: Assignment 8 Solutions}

\date{\date{}}
\maketitle
\begin{enumerate}
\item ~
\begin{enumerate}
\item From class, $Pe=e$. Therefore, $\mu^{\intercal}Pe=\mu^{\intercal}e$.
\item First, note that $\mu^{\intercal}P^{k}=((P^{k})^{\intercal}\mu)^{\intercal}=((P^{\intercal})^{k}\mu)^{\intercal}$.
Moreover,
\begin{align*}
(P^{\intercal})^{k}\mu & =(P^{\intercal})^{k-1}P^{\intercal}\mu\\
 & =(P^{\intercal})^{k-1}P^{\intercal}\left(c_{1}v_{1}+\cdots+c_{m}v_{m}\right)\\
 & =(P^{\intercal})^{k-1}\left(c_{1}\lambda_{1}v_{1}+\cdots+c_{m}\lambda_{m}v_{m}\right)\\
 & =\cdots\\
 & =c_{1}\lambda_{1}^{k}v_{1}+\cdots+c_{m}\lambda_{m}^{k}v_{m}.
\end{align*}
Therefore, $\mu^{\intercal}P^{k}=c_{1}\lambda_{1}^{k}v_{1}^{\intercal}+\cdots+c_{m}\lambda_{m}^{k}v_{m}^{\intercal}$.
\item We know $\rho(P)\leq1$ and $\lambda_{1}=1$. Therefore, $|\lambda_{j}|<1$
whenever $j\neq1$ and hence
\[
\lim_{n\rightarrow\infty}\lambda_{1}^{n}=1\qquad\text{and}\qquad\lim_{n\rightarrow\infty}\lambda_{j}^{n}=0\text{ if }j\neq1.
\]
It follows that
\begin{align*}
\lim_{n\rightarrow\infty}\mu^{\intercal}P^{n} & =\lim_{n\rightarrow\infty}\left\{ c_{1}\lambda_{1}^{n}v_{1}^{\intercal}+\cdots+c_{m}\lambda_{m}^{n}v_{m}^{\intercal}\right\} \\
 & =c_{1}v_{1}^{\intercal}\lim_{n\rightarrow\infty}\lambda_{1}^{n}+\cdots+c_{m}v_{m}^{\intercal}\lim_{n\rightarrow\infty}\lambda_{m}^{n}=c_{1}v_{1}^{\intercal}.
\end{align*}
\item This follows from the fact that products are continuous:
\[
(c_{1}v_{1}^{\intercal})P=\left(\lim_{n\rightarrow\infty}\mu^{\intercal}P^{n}\right)P=\lim_{n\rightarrow\infty}\mu^{\intercal}P^{n+1}=\lim_{n\rightarrow\infty}\mu^{\intercal}P^{n}=c_{1}v_{1}^{\intercal}.
\]
\item By part (a), we know that $(\mu^{\intercal}P^{n})e=1$ for any $n$.
Therefore,
\[
1=\lim_{n\rightarrow\infty}\left((\mu^{\intercal}P^{n})e\right)=\left(\lim_{n\rightarrow\infty}\mu^{\intercal}P^{n}\right)e=(c_{1}v_{1}^{\intercal})e.
\]
Since $v_{1}$ is a positive vector, $c_{1}$ must be positive, since
otherwise $(c_{1}v_{1}^{\intercal})e\leq0$.
\item Part (c) is akin to saying $c_{1}v_{1}^{\intercal}$ is the limiting
distribution of the Markov chain and part (d) is akin to saying that
the limiting distribution is an equilibrium/stationary distribution
of the Markov chain.
\end{enumerate}
\end{enumerate}
\pagebreak{}
\begin{enumerate}
\item[2.] ~
\begin{enumerate}
\item Simplifying completely, the answer is
\begin{equation}
\mathbb{P}(\tau\leq n)=\begin{cases}
{\displaystyle \frac{\left(1-p\right)^{n+1}}{2p-1}-\frac{p^{n+1}}{2p-1}+1} & \text{if }p\neq1/2\\
2^{-n}\left(-1+2^{n}-n\right) & \text{if }p=1/2.
\end{cases}\label{eq:expression}
\end{equation}
Below are two methods to obtain this solution.
\begin{enumerate}
\item The first method uses four states.
\begin{itemize}
\item Let $S=\{HH,HT,TH,TT\}$. The interpretation is as follows:
\begin{itemize}
\item $HH$: the most recent coin flip was $H$, immediately preceded by
$H$.
\item $HT$: the most recent coin flip was $T$, immediately preceded by
$H$.
\item $TH$: the most recent coin flip was $H$, immediately preceded by
$T$.
\item $TT$: the most recent coin flip was $T$, immediately preceded by
$T$.
\end{itemize}
\item The transitions between these states is given by the matrix
\[
\tilde{P}=\begin{pmatrix}p & 1-p\\
 &  & p & 1-p\\
p & 1-p\\
 &  & p & 1-p
\end{pmatrix}.
\]
\item In the context of our problem, this isn't quite the transition matrix
we want! That's because as soon as we encounter $HT$, the ``game''
should terminate. Therefore, we modify it to
\[
P=\begin{pmatrix}p & 1-p\\
 & 1\\
p & 1-p\\
 &  & p & 1-p
\end{pmatrix}.
\]
\item The initial distribution (i.e., the distribution of $X_{0}$) is given
by
\[
\mu^{\intercal}=\begin{pmatrix}p^{2} & p\left(1-p\right) & p\left(1-p\right) & \left(1-p\right)^{2}\end{pmatrix}.
\]
\item The terminal distribution we are interested in is
\[
\nu^{\intercal}=\begin{pmatrix}0 & 1 & 0 & 0\end{pmatrix}.
\]
\item Putting this all together, we get $\mathbb{P}(\tau\leq n)=\mu^{\intercal}P^{n-2}\nu$.
The reason we are using $n-2$ instead of $n$ here is that in the
Markov chain, $X_{0}$ corresponds to after we have already seen the
first two coin flips. You can (optionally) simplify this to get (\ref{eq:expression}).
\end{itemize}
\item The second method uses only three states. The reason we can do this
is that we are actually maintaining some redundant information in
method (\emph{i}).
\begin{itemize}
\item Let $S=\{\epsilon,H,HT\}$. The interpretation is as follows:
\begin{itemize}
\item $\epsilon$: we have not flipped any coins yet.
\item $H$: the most recent coin flip was $H$ (it is understood that if
we are in this state, we have not yet seen $HT$).
\item $HT$: the most recent coin flip was $T$, immediately preceded by
$H$.
\end{itemize}
\item The transition matrix is
\[
P=\begin{pmatrix}1-p & p\\
 & p & 1-p\\
 &  & 1
\end{pmatrix}
\]
(draw a picture of the graph to get a better sense of what is going
on).
\item The initial distribution (i.e., the distribution of $X_{0}$) is given
by
\[
\mu^{\intercal}=\begin{pmatrix}1 & 0 & 0\end{pmatrix}.
\]
\item The terminal distribution we are interested in is
\[
\nu^{\intercal}=\begin{pmatrix}0 & 0 & 1\end{pmatrix}.
\]
\item Putting this all together, $\mathbb{P}(\tau\leq n)=\mu^{\intercal}P^{n}\nu$.
You can (optionally) simplify this to get (\ref{eq:expression}).
\end{itemize}
\end{enumerate}
\item Once we have an expression for $\mathbb{P}(\tau\leq n)$, we can obtain
an expression for $\mathbb{P}(\tau=n)$ as follows. Since $\mathbb{P}(\tau=1)=0$,
we can assume $n>1$. Then,
\[
\mathbb{P}(\tau=n)=\mathbb{P}(\tau\leq n)-\mathbb{P}(\tau<n)=\mathbb{P}(\tau\leq n)-\mathbb{P}(\tau\leq n-1)
\]
(you can simplify the above further if you want to obtain an expression
like (\ref{eq:expression})).
\item Plugging in $n=10$ and $p=1/3$ into (\ref{eq:expression}), we get
\[
\mathbb{P}\left(\tau\leq10\middle|p=\frac{1}{3}\right)=\frac{57002}{59049}\approx0.96533.
\]
\end{enumerate}
\end{enumerate}

\end{document}
